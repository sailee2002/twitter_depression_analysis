{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DepressionDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEBAxkRZ-eup"
      },
      "source": [
        "# all imports\n",
        "from os import times\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import twitter_samples, stopwords\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist, classify, NaiveBayesClassifier\n",
        "import re, string, random\n",
        " "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki9RKLMd_NjG"
      },
      "source": [
        "## **TWEET EXTRACTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgAAh0lB-p8R"
      },
      "source": [
        "CONSUMER_KEY='8V4toASRqwVLXtP7yp1pKJICv'\n",
        "CONSUMER_SECRET='TDEVVQ5LBgXGzwXZKne2OAgNapIAeBSCREhLyDwvfZs8RaAO4D'\n",
        "ACCESS_KEY='1312978936037552128-NZ0WXcyfuNzJ98AbxLkuts5TVklx9h'\n",
        "ACCESS_SECRET='qJZ53s1rx6n0UUmIkjxuyXWKigF237qLCxLdPGONOjkcx'\n",
        "auth=tweepy.OAuthHandler(CONSUMER_KEY,CONSUMER_SECRET)\n",
        "auth.set_access_token(ACCESS_KEY,ACCESS_SECRET)\n",
        "auth.secure=True\n",
        "api=tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMgHJBoh-tcO"
      },
      "source": [
        "def extraction():\n",
        "\n",
        "    searchQuery = 'Covid 19'\n",
        "    count = 1\n",
        "    try:\n",
        "        # Creation of query method using parameters\n",
        "        tweets = tweepy.Cursor(api.search,q=searchQuery).items(count)\n",
        "        \n",
        "        # Pulling information from tweets iterable object\n",
        "        tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "    \n",
        "    # Creation of dataframe from tweets list\n",
        "    # Add or remove columns as you remove tweet information\n",
        "        tweets_df = pd.DataFrame(tweets_list)\n",
        "    \n",
        "    except BaseException as e:\n",
        "        print('failed on_status,',str(e))\n",
        "        times.sleep(3)\n",
        "        \n",
        "    q=searchQuery\n",
        "    tweetsPerQry=1\n",
        "    fName='newFile.txt'\n",
        "    sinceId=None\n",
        "    max_id= -1\n",
        "    maxTweets=1\n",
        "    tweetCount=0\n",
        "    print(\"downloading\".format(maxTweets))\n",
        "    with open(fName ,'w') as f:\n",
        "        while tweetCount<maxTweets:\n",
        "            tweets=[]\n",
        "            try:\n",
        "                if(max_id<=0):\n",
        "                    if(not sinceId):\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,tweet_mode='extended')\n",
        "                    else:\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,since_id=sinceId,tweet_mode='extended')\n",
        "                else:\n",
        "                    if(not sinceId):\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,max_id=str(max_id-1),tweet_mode='extended')\n",
        "                    else:\n",
        "                        new_tweets=api.search(q=q,lang=\"en\",count=tweetsPerQry,max_id=str(max_id-1),since_id=sinceId,tweet_mode='extended')\n",
        "        \n",
        "                if not new_tweets:\n",
        "                    print(\"no more tweets found\")\n",
        "                    break\n",
        "                for tweet in new_tweets:\n",
        "                    f.write(str(tweet.full_text.replace('\\n','').encode(\"utf-8\"))+\"\\n\")\n",
        "        \n",
        "                tweetCount+=len(new_tweets)\n",
        "                print(\"Downloaded {0} tweets\".format(tweetCount))\n",
        "                max_id=new_tweets[-1].id\n",
        "        \n",
        "            except tweepy.TweepError as e:\n",
        "                print(\"Some error: \"+str(e))\n",
        "                break\n",
        "        \n",
        "    print (\"Downloaded {0} tweets , saved to {1}\".format(tweetCount,fName)) \n",
        "\n",
        "\n",
        "    f_1 = open(\"newFile.txt\", \"r\")\n",
        "    print(\" The tweet is: \")\n",
        "    read_tweet = f_1.read() \n",
        "    print(read_tweet)                                          \n",
        "\n",
        "    return read_tweet\n",
        "    \n",
        "    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpO9TJa_UuV"
      },
      "source": [
        "# **`PREPROCESSING ON TWEETS`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxoFeUsk_Glc"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "#from extract_tweets import extraction"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhjiHrrt__2u"
      },
      "source": [
        "# read_tweet1 = extraction()\n",
        "\n",
        "\n",
        "def processing():\n",
        "    text = extraction()\n",
        "\n",
        "    #print(read_tweet1)\n",
        "    # remove url\n",
        "    import re\n",
        "    pattern=r'(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))';\n",
        "    match = re.findall(pattern, text)\n",
        "    for m in match:\n",
        "        url = m[0]\n",
        "        text = text.replace(url, '')\n",
        "\n",
        "    # remove mentions\n",
        "    text1 = re.sub('@[^\\s]+','',text)\n",
        "    # text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    t_withoutMentions = re.sub(r'^RT[\\s]+', '', text1)\n",
        "    t3=t_withoutMentions\n",
        "\n",
        "  \n",
        "    #def handle_emojis(t3):\n",
        "        # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
        "    t3 = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' Happy ', t3)\n",
        "        # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
        "    t3 = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' Laugh ', t3)\n",
        "        # Love -- <3, :*\n",
        "    t3 = re.sub(r'(<3|:\\*)', ' Love ', t3)\n",
        "        # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
        "    t3 = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' Wink ', t3)\n",
        "        # Sad -- :-(, : (, :(, ):, )-:\n",
        "    t3 = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' Sad ', t3)\n",
        "        # Cry -- :,(, :'(, :\"(\n",
        "    t3 = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' Cry ', t3)\n",
        "    \n",
        "    phrase= t3\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"cannot\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \"are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \"is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \"would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \"will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \"have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \"am\", phrase)\n",
        "\n",
        "    \n",
        "\n",
        "    #open the fle slang.txt \n",
        "    file=open(\"slang2.txt\",\"r\") \n",
        "    slang=file.read() \n",
        "    ts=phrase\n",
        "    ts=ts.upper()\n",
        "    #seperating each line present in the file \n",
        "    slang=slang.split('\\n') \n",
        "        \n",
        "    tweet_tokens=ts.split() \n",
        "    slang_word=[] \n",
        "    meaning=[] \n",
        "        \n",
        "    #store the slang words and meanings in different lists \n",
        "    for line in slang: \n",
        "        temp=line.split(\"=\") \n",
        "        slang_word.append(temp[0]) \n",
        "        meaning.append(temp[-1]) \n",
        "        \n",
        "    #replace the slang word with meaning \n",
        "    for i,word in enumerate(tweet_tokens): \n",
        "        if word in slang_word: \n",
        "            idx=slang_word.index(word) \n",
        "            tweet_tokens[i]=meaning[idx] \n",
        "\n",
        "    \n",
        "\n",
        "    ts1=\" \".join(tweet_tokens) \n",
        "    phrase1=ts1\n",
        "    phrase1 = re.sub(r\"won\\'t\", \"will not\", phrase1)\n",
        "    phrase1 = re.sub(r\"can\\'t\", \"can not\", phrase1)\n",
        "\n",
        "    # general\n",
        "    phrase1 = re.sub(r\"n\\'t\", \"not\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'re\", \"are\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'s\", \"is\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'d\", \"would\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'ll\", \"will\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'t\", \"not\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'ve\", \"have\", phrase1)\n",
        "    phrase1 = re.sub(r\"\\'m\", \"am\", phrase1)\n",
        "\n",
        "    \n",
        "\n",
        "    punc = '''?@#$%^&*_~'''\n",
        "        \n",
        "    for ele in phrase1:  \n",
        "        if ele in punc:  \n",
        "            phrase1 = phrase1.replace(ele, \" \")  \n",
        "\n",
        "    \n",
        "    # # tokenization\n",
        "    # t10 = word_tokenize(phrase1)\n",
        "   \n",
        "    # def listToString(t10):  \n",
        "            \n",
        "    #     # initialize an empty string \n",
        "    #     t0 = \"\"\n",
        "    #     return (t0.join(t10))           \n",
        "    # t0 = listToString(t10)  \n",
        "    \n",
        "    # # remove puntuations\n",
        "    # punc = '''!()-[]{};:\"\\,<>./?@#$%^&*_~'''\n",
        "    # for ele in t0:  \n",
        "    #     if ele in punc:  \n",
        "    #         t0 = t0.replace(ele, \" \")\n",
        "\n",
        "  \n",
        "    # print (phrase1)\n",
        "    return phrase1\n",
        "\n",
        "\n",
        "# processing()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSORfQje-2z6"
      },
      "source": [
        "def preprocess(phrase1):\n",
        "  processing()\n",
        "  return phrase1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7uCIyYWAEgG"
      },
      "source": [
        "# **NAIVE BAYES CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "gGd9u4AsADeI",
        "outputId": "9f66a815-e579-4c32-b294-509152bbe7ca"
      },
      "source": [
        "import pandas as pd\n",
        "#importing the dataset\n",
        "df = pd.read_csv(\"10000TweetsDataset1.csv\", encoding = \"ISO-8859-1\")\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>isPlayer Has Died! Sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>well it's time for me to go to skewl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@toonstopia wonder why you ain't be able to st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@mingmingming uuugh fb is taking too long to l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>does not feel like working today</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                               text\n",
              "0  negative                          isPlayer Has Died! Sorry \n",
              "1  negative              well it's time for me to go to skewl \n",
              "2  negative  @toonstopia wonder why you ain't be able to st...\n",
              "3  negative  @mingmingming uuugh fb is taking too long to l...\n",
              "4  negative                  does not feel like working today "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "jCij57V5AYVn",
        "outputId": "a8eb2545-a782-4e8d-87a5-655c8f13c4d8"
      },
      "source": [
        "df.groupby('sentiment').describe()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>negative</th>\n",
              "      <td>4999</td>\n",
              "      <td>4984</td>\n",
              "      <td>isPlayer Has Died! Sorry</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>5000</td>\n",
              "      <td>4992</td>\n",
              "      <td>@MrMusselman 4hours boom boom  http://www.4hou...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           text                                                               \n",
              "          count unique                                                top freq\n",
              "sentiment                                                                     \n",
              "negative   4999   4984                          isPlayer Has Died! Sorry    10\n",
              "positive   5000   4992  @MrMusselman 4hours boom boom  http://www.4hou...    2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "NJfXkvBEAdMB",
        "outputId": "58cfca1e-72af-4a41-833a-3d7c3268e522"
      },
      "source": [
        "# ml models understand numbers not text\n",
        "df['category']=df['sentiment'].apply(lambda x: 1 if x=='positive' else 0)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>isPlayer Has Died! Sorry</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>well it's time for me to go to skewl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>@toonstopia wonder why you ain't be able to st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@mingmingming uuugh fb is taking too long to l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>does not feel like working today</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment                                               text  category\n",
              "0  negative                          isPlayer Has Died! Sorry          0\n",
              "1  negative              well it's time for me to go to skewl          0\n",
              "2  negative  @toonstopia wonder why you ain't be able to st...         0\n",
              "3  negative  @mingmingming uuugh fb is taking too long to l...         0\n",
              "4  negative                  does not feel like working today          0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQtAgIyAf4O"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text,df.category)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBivLo6fAkLf",
        "outputId": "ba7247ad-e441-4f56-9de7-7bddd2f4401d"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "v = CountVectorizer()\n",
        "X_train_count = v.fit_transform(X_train.values)\n",
        "X_train_count.toarray()[:2]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMsjhV1KAl-O",
        "outputId": "88974698-bfb6-41a0-a3d0-4a467b0eb665"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_count,y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4czQ-HrApxC",
        "outputId": "05edd98c-8a0d-493d-c27b-429a202dc128"
      },
      "source": [
        "tweet_sample = [\n",
        "    'I am really not at all happy'\n",
        "    \n",
        "]\n",
        "tweet_count = v.transform(tweet_sample)\n",
        "model.predict(tweet_count)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp2a2ByBV5AK",
        "outputId": "5bcba270-93c3-45d9-f6e3-05b8c1769aee"
      },
      "source": [
        " import nltk\n",
        " nltk.download('punkt')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naT0Q5CxVc_0"
      },
      "source": [
        "# def calling():\n",
        "#     for counter in range(1):\n",
        "#         extraction()\n",
        "#         processing()\n",
        "#         #naiveclassify()\n",
        "#         print(\"======================================================\")\n",
        "#         print(\"=====================================================\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     calling()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_XS-cAVTl8",
        "outputId": "25bc3b42-68ca-4102-a3e2-7428af676f6d"
      },
      "source": [
        "\n",
        "\n",
        "tweet_sample = [\n",
        "    processing()\n",
        "    \n",
        "]\n",
        "tweet_count = v.transform(tweet_sample)\n",
        "model.predict(tweet_count)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @bennydiego: Fact: A well known side effect of being unvaccinated is death. 15 Staff Members In One Florida School District Die Of Cov\\xe2\\x80\\xa6'\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfZ5UgK7QtKT"
      },
      "source": [
        "###########################\n",
        "\n",
        "def naive_classifier():\n",
        "\n",
        "  tweet_sample = [\n",
        "      processing()\n",
        "      \n",
        "  ]\n",
        "  \n",
        "  tweet_count = v.transform(tweet_sample)\n",
        "  print(\"CLASSIFICATION USING NAIVE BAYES\")\n",
        "  print(model.predict(tweet_count))\n",
        "\n",
        "# naive_classifier()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DucR31FpAskz",
        "outputId": "8becf32e-95c2-480c-c72c-be5acda1edf2"
      },
      "source": [
        "X_test_count = v.transform(X_test)\n",
        "model.score(X_test_count, y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7684"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_yjCMg_rWX2"
      },
      "source": [
        "# **LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBMrj64zwvC"
      },
      "source": [
        "# libratries for data manupulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns #plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzIxAE37z0m3"
      },
      "source": [
        "sns.set_style('darkgrid') # setting the bg to darkgrid"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHnoC6Fez238"
      },
      "source": [
        "columns = ['sentiment1', 'text', 'date', 'loc']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJjhnM6vz4X2"
      },
      "source": [
        "df = pd.read_csv('10000TweetsDataset1.csv', header = None, names = columns,  encoding='ISO-8859-1')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lz9m_14Qz53d",
        "outputId": "0111d583-8c42-4f08-e79e-a445ef5e5eb6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment1</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>loc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentiment</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>isPlayer Has Died! Sorry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>well it's time for me to go to skewl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@toonstopia wonder why you ain't be able to st...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@mingmingming uuugh fb is taking too long to l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment1                                               text  date  loc\n",
              "0  sentiment                                               text   NaN  NaN\n",
              "1   negative                          isPlayer Has Died! Sorry    NaN  NaN\n",
              "2   negative              well it's time for me to go to skewl    NaN  NaN\n",
              "3   negative  @toonstopia wonder why you ain't be able to st...   NaN  NaN\n",
              "4   negative  @mingmingming uuugh fb is taking too long to l...   NaN  NaN"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Gp-hmtco0IR4",
        "outputId": "aaddb743-239b-4c0e-f8d8-c5e26aca828e"
      },
      "source": [
        "# ml models understand numbers not text\n",
        "# thus converting sentiment to value (1/0)\n",
        "df['category'] = df['sentiment1'].apply(lambda x: 0 if x=='negative' else 1)\n",
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment1</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>loc</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentiment</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>isPlayer Has Died! Sorry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>well it's time for me to go to skewl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@toonstopia wonder why you ain't be able to st...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@mingmingming uuugh fb is taking too long to l...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentiment1                                               text  ...  loc  category\n",
              "0  sentiment                                               text  ...  NaN         1\n",
              "1   negative                          isPlayer Has Died! Sorry   ...  NaN         0\n",
              "2   negative              well it's time for me to go to skewl   ...  NaN         0\n",
              "3   negative  @toonstopia wonder why you ain't be able to st...  ...  NaN         0\n",
              "4   negative  @mingmingming uuugh fb is taking too long to l...  ...  NaN         0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsHICWC00Jpp",
        "outputId": "d410358e-8a8a-4759-8433-e5bc5e4812c6"
      },
      "source": [
        "num_tweets = len(df) # total tweets in dataset\n",
        "num_pos_tweets = len(df[df['category'] == 1])\n",
        "num_neg_tweets = len(df[df['category'] == 0])\n",
        "print(\"Total Number of tweets in the dataset = {}\".format(num_tweets))\n",
        "print(\"Total Number of positive tweets = {}\".format(num_pos_tweets))\n",
        "print(\"Total Number of negative tweets = {}\".format(num_neg_tweets))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of tweets in the dataset = 10000\n",
            "Total Number of positive tweets = 5001\n",
            "Total Number of negative tweets = 4999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n313NEHk0Mgz"
      },
      "source": [
        "all_positive_tweets = list(df[df['category'] == 1]['text'])\n",
        "all_negative_tweets = list(df[df['category'] == 0]['text'])\n",
        "# print(all_negative_tweets[0])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmxYY07V0N54"
      },
      "source": [
        "# if we take the large dataset\n",
        "# selecting only a portion of data due large size\n",
        "# select_prop = .25\n",
        "# all_positive_tweets = all_positive_tweets[:int(len(all_positive_tweets)*select_prop)]\n",
        "# all_negative_tweets = all_negative_tweets[:int(len(all_negative_tweets)*select_prop)]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0eeJ0fi0QNj"
      },
      "source": [
        "train_split = 0.8    # ratio to be splitted in\n",
        "\n",
        "train_pos = all_positive_tweets[:int(len(all_positive_tweets)*train_split)]\n",
        "train_neg = all_negative_tweets[:int(len(all_negative_tweets)*train_split)]\n",
        "\n",
        "test_pos = all_positive_tweets[int(len(all_positive_tweets)*train_split):]\n",
        "test_neg = all_negative_tweets[int(len(all_negative_tweets)*train_split):]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.concatenate((np.ones(len(train_pos)), np.zeros(len(train_neg))))\n",
        "test_y = np.concatenate((np.ones(len(test_pos)), np.zeros(len(test_neg))))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NBPt7050T2W",
        "outputId": "374daa0b-aa23-410d-f54c-8de41daab857"
      },
      "source": [
        "print(\"Number of training samples - \", len(train_x))\n",
        "print(\"Numner of test samples - \", len(test_x))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples -  7999\n",
            "Numner of test samples -  2001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcIRhTFT0UgO"
      },
      "source": [
        "def process_tweet(tweet):\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "# processing()\n",
        "\n",
        "def build_freqs(tweets, ys):\n",
        "\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dX44Q690XrU",
        "outputId": "70664424-ba21-4f94-ea67-af26bd32b5a6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0La8Q4q0aoJ"
      },
      "source": [
        "freqs = build_freqs(train_x, train_y)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeXpXYVX0cET"
      },
      "source": [
        "# sigmoid function\n",
        "def sigmoid(z):\n",
        "    h = 1/(1 + np.exp(-z))\n",
        "    return h\n",
        "\n",
        "#gradient descent algorithm \n",
        "def StochasticGradientDescent(x, y, theta, alpha, num_iters, batch_per_itr, batch_size):\n",
        "    \n",
        "    # x is matrix of features\n",
        "    # theta = wt. vector\n",
        "    # m = the number of rows in matrix x\n",
        "    # J = final cost\n",
        "    m =  x.shape[0]\n",
        "    loss = []\n",
        "    for itr in range(0, num_iters):\n",
        "        \n",
        "        for i in range(batch_per_itr):\n",
        "            batch = np.random.randint(0, m, size=batch_size)\n",
        "            x_train = x[batch,:]\n",
        "            y_train = y[batch,:]\n",
        "            \n",
        "            # get z, the dot product of x and theta\n",
        "            z = np.dot(x_train, theta)\n",
        "        \n",
        "            # get the sigmoid of z\n",
        "            h = sigmoid(z)\n",
        "        \n",
        "            # calculate the cost function\n",
        "            J = -1/batch_size * (np.dot(np.transpose(y_train),np.log(h)) + np.dot(np.transpose(1 - y_train), np.log(1 - h)))\n",
        "            \n",
        "            # update the weights theta\n",
        "            theta = theta - ( alpha/m * np.dot(np.transpose(x_train), (h - y_train)))\n",
        "        if not itr%10 and itr:\n",
        "            print(\"Completed {} iterations, loss = {}\".format(itr, np.squeeze(J))) \n",
        "        loss.append(J)\n",
        "    J = float(J)\n",
        "    return J, theta, loss\n",
        "\n",
        "# extracting features and storing them in matrix\n",
        "# 1st feature: no. of +ve words in tweet\n",
        "# 2nd: no. of -ve words\n",
        "def extract_features(tweet, freqs):\n",
        "   \n",
        "    word_l = process_tweet(tweet)\n",
        "    \n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3)) \n",
        "    \n",
        "    #bias term = 1\n",
        "    x[0,0] = 1 \n",
        "    \n",
        "    \n",
        "    # loop through each word \n",
        "    for word in word_l:\n",
        "        pos_pair = (word, 1.0)\n",
        "        neg_pair = (word, 0.0)\n",
        "        if pos_pair in freqs.keys():\n",
        "            # increment the word count for the positive label 1\n",
        "            x[0,1] += freqs[pos_pair]\n",
        "        if neg_pair in freqs.keys():\n",
        "            # increment the word count for the negative label 0\n",
        "            x[0,2] += freqs[neg_pair]\n",
        "        \n",
        "        \n",
        "    assert(x.shape == (1, 3))\n",
        "    return x\n",
        "\n",
        "\n",
        "def predict_tweet(tweet, freqs, theta):\n",
        "    \n",
        "    # extract the features of the tweet and store it into x\n",
        "    x = extract_features(tweet, freqs)\n",
        "    \n",
        "    # make the prediction using x and theta\n",
        "    y_pred = sigmoid(np.dot(x, theta))\n",
        "    \n",
        "    \n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    \n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "    m = test_y.shape[0]\n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = predict_tweet(tweet, freqs, theta)\n",
        "        \n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0)\n",
        "\n",
        "   \n",
        "   \n",
        "    y_hat = np.array(y_hat)\n",
        "    y_hat = np.reshape(y_hat, (m, 1))\n",
        "    accuracy = np.sum(y_hat == test_y)/m\n",
        "    \n",
        "    return accuracy\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdKfibKg0db3"
      },
      "source": [
        "X = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X[i, :]= extract_features(train_x[i], freqs)\n",
        " \n",
        "\n",
        "Y = train_y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbDWf-940gNU"
      },
      "source": [
        "Y = np.reshape(Y, (-1,1))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU8TQ87-0hv-"
      },
      "source": [
        "# shuffle data\n",
        "s = np.random.permutation(range(len(X)))\n",
        "X = X[s]\n",
        "Y = Y[s]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74q9LKNN0jLW",
        "outputId": "338fef0f-0416-4a26-f3f1-62c306badbc0"
      },
      "source": [
        "J, theta, loss_logs = StochasticGradientDescent(X, Y, theta = np.zeros((3, 1)), alpha=1e-9, num_iters=100, batch_per_itr=50, batch_size=100000) \n",
        "print(f\"The cost after traill ning is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 10 iterations, loss = 0.6893493136171217\n",
            "Completed 20 iterations, loss = 0.686386928710329\n",
            "Completed 30 iterations, loss = 0.6837089938519259\n",
            "Completed 40 iterations, loss = 0.680852380730113\n",
            "Completed 50 iterations, loss = 0.6787208163410994\n",
            "Completed 60 iterations, loss = 0.6759197938696923\n",
            "Completed 70 iterations, loss = 0.673676793048483\n",
            "Completed 80 iterations, loss = 0.6714404496363149\n",
            "Completed 90 iterations, loss = 0.6688941686070156\n",
            "The cost after traill ning is 0.66690196.\n",
            "The resulting vector of weights is [7.4e-07, 0.00089168, -0.00089404]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "EVLkHBAK0lzo",
        "outputId": "1edc38d9-b4cc-4e06-9b62-4e53bece9cbb"
      },
      "source": [
        "plt.plot(np.squeeze(loss_logs))\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fesrudzz0oC3",
        "outputId": "f90f6afb-ae88-4dc3-961b-458506ac1788"
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, np.reshape(test_y, (-1,1)), freqs, theta)\n",
        "print(tmp_accuracy)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6776611694152923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDiwoKT0qPT",
        "outputId": "b5c940d0-7b49-45a9-e1e2-8756edeafbad"
      },
      "source": [
        "# example\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.468705]]\n",
            "Negative sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGG_DMb41IZm",
        "outputId": "f26a73c7-c023-48dc-a92c-c6fba5f1db6c"
      },
      "source": [
        "my_tweet =  processing()\n",
        "print(my_tweet)\n",
        "y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b\"RT @BernieSpofforth: I will never vote for any MP who did not vocally stand against vaccine passports. I don't care what party they repre\\xe2\\x80\\xa6\"\n",
            "\n",
            "B\"RT I WILL NEVER VOTE FOR ANY MP WHO DID NOT VOCALLY STAND AGAINST VACCINE PASSPORTS. I DONOT CARE WHAT PARTY THEY REPRE\\XE2\\X80\\XA6\"\n",
            "[[0.50194402]]\n",
            "Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6tykWu_fAOS",
        "outputId": "3e7b7b0a-46be-4f45-cf6e-eaaa93564d05"
      },
      "source": [
        "def logistic_classifier():\n",
        "  my_tweet =  processing()\n",
        "  print(my_tweet)\n",
        "  y_hat = predict_tweet(my_tweet, freqs, theta)\n",
        "  print(y_hat)\n",
        "  if y_hat > 0.5:\n",
        "      print('Positive sentiment')\n",
        "  else: \n",
        "      print('Negative sentiment')\n",
        "\n",
        "print(\"CLASSIFICATION USING LOGISTIC REGRESSION:\")\n",
        "logistic_classifier()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION USING LOGISTIC REGRESSION:\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b\"RT @BernieSpofforth: I will never vote for any MP who did not vocally stand against vaccine passports. I don't care what party they repre\\xe2\\x80\\xa6\"\n",
            "\n",
            "B\"RT I WILL NEVER VOTE FOR ANY MP WHO DID NOT VOCALLY STAND AGAINST VACCINE PASSPORTS. I DONOT CARE WHAT PARTY THEY REPRE\\XE2\\X80\\XA6\"\n",
            "[[0.50194402]]\n",
            "Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fitnK5HPy97"
      },
      "source": [
        "# **MAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvAQaAGF3yc1"
      },
      "source": [
        "#################\n",
        "# extract tweets:\n",
        "# extraction()\n",
        "\n",
        "# preprocessing:\n",
        "# processing()\n",
        "\n",
        "# naive bayes classification\n",
        "# naive_classifer()\n",
        "\n",
        "# logistic regression classifier\n",
        "# logistic_classifier()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfK2s-2rP336",
        "outputId": "17a9d0c7-1530-449e-ef8f-efb566b673ef"
      },
      "source": [
        "import time\n",
        "\n",
        "def calling():\n",
        "    for counter in range(2):\n",
        "        # extraction()\n",
        "        # processing()\n",
        "        naive_classifier()\n",
        "        print(\"======================================================\")\n",
        "        logistic_classifier()\n",
        "        print(\"======================================================\")\n",
        "        print(\"======================================================\")\n",
        "        time.sleep(20)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    calling()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b\"RT @BernieSpofforth: I will never vote for any MP who did not vocally stand against vaccine passports. I don't care what party they repre\\xe2\\x80\\xa6\"\n",
            "\n",
            "CLASSIFICATION USING NAIVE BAYES\n",
            "[0]\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b\"RT @BernieSpofforth: I will never vote for any MP who did not vocally stand against vaccine passports. I don't care what party they repre\\xe2\\x80\\xa6\"\n",
            "\n",
            "B\"RT I WILL NEVER VOTE FOR ANY MP WHO DID NOT VOCALLY STAND AGAINST VACCINE PASSPORTS. I DONOT CARE WHAT PARTY THEY REPRE\\XE2\\X80\\XA6\"\n",
            "[[0.50194402]]\n",
            "Positive sentiment\n",
            "======================================================\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @trishgreenhalgh: To counter some of the shocking misinformation circulating today:COVID-19 is a serious &amp; potentially lethal disease.\\xe2\\x80\\xa6'\n",
            "\n",
            "CLASSIFICATION USING NAIVE BAYES\n",
            "[1]\n",
            "======================================================\n",
            "downloading\n",
            "Downloaded 1 tweets\n",
            "Downloaded 1 tweets , saved to newFile.txt\n",
            " The tweet is: \n",
            "b'RT @trishgreenhalgh: To counter some of the shocking misinformation circulating today:COVID-19 is a serious &amp; potentially lethal disease.\\xe2\\x80\\xa6'\n",
            "\n",
            "B'RT TO COUNTER SOME OF THE SHOCKING MISINFORMATION CIRCULATING IS A SERIOUS  AMP; POTENTIALLY LETHAL DISEASE.\\XE2\\X80\\XA6'\n",
            "[[0.49865324]]\n",
            "Negative sentiment\n",
            "======================================================\n",
            "======================================================\n"
          ]
        }
      ]
    }
  ]
}